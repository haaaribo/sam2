# SAM 2: ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ì—ì„œ ëª¨ë“  ê²ƒì„ ì„¸ê·¸ë¨¼íŠ¸í™”

**[Metaì˜ AI, FAIR](https://ai.meta.com/research/)**

[Nikhila Ravi](https://nikhilaravi.com/), [Valentin Gabeur](https://gabeur.github.io/), [Yuan-Ting Hu](https://scholar.google.com/citations?user=E8DVVYQAAAAJ&hl=en), [Ronghang Hu](https://ronghanghu.com/), [Chaitanya Ryali](https://scholar.google.com/citations?user=4LWx24UAAAAJ&hl=en), [Tengyu Ma](https://scholar.google.com/citations?user=VeTSl0wAAAAJ&hl=en), [Haitham Khedr](https://hkhedr.com/), [Roman RÃ¤dle](https://scholar.google.de/citations?user=Tpt57v0AAAAJ&hl=en), [Chloe Rolland](https://scholar.google.com/citations?hl=fr&user=n-SnMhoAAAAJ), [Laura Gustafson](https://scholar.google.com/citations?user=c8IpF9gAAAAJ&hl=en), [Eric Mintun](https://ericmintun.github.io/), [Junting Pan](https://junting.github.io/), [Kalyan Vasudev Alwala](https://scholar.google.co.in/citations?user=m34oaWEAAAAJ&hl=en), [Nicolas Carion](https://www.nicolascarion.com/), [Chao-Yuan Wu](https://chaoyuan.org/), [Ross Girshick](https://www.rossgirshick.info/), [Piotr DollÃ¡r](https://pdollar.github.io/), [Christoph Feichtenhofer](https://feichtenhofer.github.io/)

[[`ë…¼ë¬¸`](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/)] [[`í”„ë¡œì íŠ¸`](https://ai.meta.com/sam2)] [[`ë°ëª¨`](https://sam2.metademolab.com/)] [[`ë°ì´í„°ì…‹`](https://ai.meta.com/datasets/segment-anything-video)] [[`ë¸”ë¡œê·¸`](https://ai.meta.com/blog/segment-anything-2)] [[`BibTeX`](#citing-sam-2)]

![SAM 2 ì•„í‚¤í…ì²˜](assets/model_diagram.png?raw=true)

**Segment Anything Model 2 (SAM 2)**ëŠ” ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ëŠ¥í•œ ì‹œê°ì  ì„¸ê·¸ë¨¼íŠ¸í™”ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ê¸°ì´ˆ ëª¨ë¸ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‹¨ì¼ í”„ë ˆì„ì˜ ë¹„ë””ì˜¤ë¡œ ì´ë¯¸ì§€ë¥¼ ê³ ë ¤í•˜ì—¬ SAMì„ ë¹„ë””ì˜¤ë¡œ í™•ì¥í•©ë‹ˆë‹¤. ëª¨ë¸ ì„¤ê³„ëŠ” ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ë©”ëª¨ë¦¬ë¥¼ ê°–ì¶˜ ê°„ë‹¨í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ í†µí•´ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ê°œì„ í•˜ëŠ” ëª¨ë¸-ì¸-ë£¨í”„ ë°ì´í„° ì—”ì§„ì„ êµ¬ì¶•í•˜ì—¬ [**ìš°ë¦¬ì˜ SA-V ë°ì´í„°ì…‹**](https://ai.meta.com/datasets/segment-anything-video)ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì´ëŠ” í˜„ì¬ê¹Œì§€ ê°€ì¥ í° ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸í™” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ëœ SAM 2ëŠ” ë‹¤ì–‘í•œ ì‘ì—…ê³¼ ì‹œê°ì  ë„ë©”ì¸ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

![SA-V ë°ì´í„°ì…‹](assets/sa_v_dataset.jpg?raw=true)

## ìµœì‹  ì—…ë°ì´íŠ¸

**2024ë…„ 12ì›” 11ì¼ -- ì£¼ìš” VOS ì†ë„ í–¥ìƒì„ ìœ„í•œ ì „ì²´ ëª¨ë¸ ì»´íŒŒì¼ ë° ë‹¤ì¤‘ ê°ì²´ ì¶”ì ì„ ë” ì˜ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ `SAM2VideoPredictor`**

- ì´ì œ ë¹„ë””ì˜¤ì—ì„œ ì „ì²´ SAM 2 ëª¨ë¸ì˜ `torch.compile`ì„ ì§€ì›í•˜ë©°, `build_sam2_video_predictor`ì—ì„œ `vos_optimized=True`ë¡œ ì„¤ì •í•˜ë©´ VOS ì¶”ë¡  ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.
- ìš°ë¦¬ëŠ” `SAM2VideoPredictor`ì˜ êµ¬í˜„ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ë…ë¦½ì ì¸ ê°ì²´ë³„ ì¶”ë¡ ì„ ì§€ì›í•˜ë©°, ë‹¤ì¤‘ ê°ì²´ ì¶”ì ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ê°€ì •ì„ ì™„í™”í•˜ê³  ì¶”ì ì´ ì‹œì‘ëœ í›„ ìƒˆë¡œìš´ ê°ì²´ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìì„¸í•œ ë‚´ìš©ì€ [`RELEASE_NOTES.md`](RELEASE_NOTES.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

**2024ë…„ 9ì›” 30ì¼ -- SAM 2.1 ê°œë°œì ìŠ¤ìœ„íŠ¸ (ìƒˆë¡œìš´ ì²´í¬í¬ì¸íŠ¸, í›ˆë ¨ ì½”ë“œ, ì›¹ ë°ëª¨) ì¶œì‹œ**

- ê°œì„ ëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì˜ ìƒˆë¡œìš´ ìŠ¤ìœ„íŠ¸ (SAM 2.1ë¡œ ëª…ëª…ë¨)ê°€ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ëª¨ë¸ ì„¤ëª…](#model-description)ì„ ì°¸ì¡°í•˜ì„¸ìš”.
  * ìƒˆë¡œìš´ SAM 2.1 ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì´ ì €ì¥ì†Œì˜ ìµœì‹  ëª¨ë¸ ì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ì „ ë²„ì „ì˜ ì €ì¥ì†Œë¥¼ ì„¤ì¹˜í•œ ê²½ìš°, ë¨¼ì € `pip uninstall SAM-2`ë¥¼ í†µí•´ ì´ì „ ë²„ì „ì„ ì œê±°í•˜ê³ , ì´ ì €ì¥ì†Œì—ì„œ ìµœì‹  ì½”ë“œë¥¼ ê°€ì ¸ì˜¨ í›„ (`git pull`), ì•„ë˜ [ì„¤ì¹˜](#installation)ë¥¼ ë”°ë¼ ì €ì¥ì†Œë¥¼ ë‹¤ì‹œ ì„¤ì¹˜í•˜ì„¸ìš”.
- í›ˆë ¨ (ë° ë¯¸ì„¸ ì¡°ì •) ì½”ë“œê°€ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì‹œì‘í•˜ëŠ” ë°©ë²•ì€ [`training/README.md`](training/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
- SAM 2 ì›¹ ë°ëª¨ì˜ í”„ë¡ íŠ¸ì—”ë“œ + ë°±ì—”ë“œ ì½”ë“œê°€ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [`demo/README.md`](demo/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì„¤ì¹˜

SAM 2ëŠ” ì‚¬ìš© ì „ì— ë¨¼ì € ì„¤ì¹˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ ì½”ë“œëŠ” `python>=3.10`, `torch>=2.5.1` ë° `torchvision>=0.20.1`ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. PyTorch ë° TorchVision ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ë ¤ë©´ [ì—¬ê¸°](https://pytorch.org/get-started/locally/)ì˜ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”. GPU ë¨¸ì‹ ì— SAM 2ë¥¼ ì„¤ì¹˜í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì„¸ìš”:

```bash
git clone https://github.com/facebookresearch/sam2.git && cd sam2

pip install -e .
```
Windowsì— ì„¤ì¹˜í•˜ëŠ” ê²½ìš°, [Windows Subsystem for Linux (WSL)](https://learn.microsoft.com/en-us/windows/wsl/install)ê³¼ Ubuntuë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°•ë ¥íˆ ê¶Œì¥ë©ë‹ˆë‹¤.

SAM 2 ì˜ˆì¸¡ê¸°ë¥¼ ì‚¬ìš©í•˜ê³  ì˜ˆì œ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ë ¤ë©´ `jupyter`ì™€ `matplotlib`ê°€ í•„ìš”í•˜ë©° ë‹¤ìŒì„ í†µí•´ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
pip install -e ".[notebooks]"
```

ì°¸ê³ :
1. ì´ ì„¤ì¹˜ë¥¼ ìœ„í•´ [Anaconda](https://www.anaconda.com/)ë¥¼ í†µí•´ ìƒˆë¡œìš´ Python í™˜ê²½ì„ ìƒì„±í•˜ê³  https://pytorch.org/ë¥¼ ë”°ë¼ `pip`ì„ í†µí•´ PyTorch 2.5.1 (ë˜ëŠ” ê·¸ ì´ìƒ)ì„ ì„¤ì¹˜í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤. í˜„ì¬ í™˜ê²½ì— PyTorch ë²„ì „ì´ 2.5.1ë³´ë‹¤ ë‚®ì€ ê²½ìš°, ìœ„ì˜ ì„¤ì¹˜ ëª…ë ¹ì€ `pip`ì„ ì‚¬ìš©í•˜ì—¬ ìµœì‹  PyTorch ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ë ¤ê³  ì‹œë„í•  ê²ƒì…ë‹ˆë‹¤.
2. ìœ„ ë‹¨ê³„ëŠ” `nvcc` ì»´íŒŒì¼ëŸ¬ë¡œ ì‚¬ìš©ì ì •ì˜ CUDA ì»¤ë„ì„ ì»´íŒŒì¼í•˜ëŠ” ê²ƒì„ ìš”êµ¬í•©ë‹ˆë‹¤. ë¨¸ì‹ ì— ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°, PyTorch CUDA ë²„ì „ì— ë§ëŠ” [CUDA ë„êµ¬í‚·](https://developer.nvidia.com/cuda-toolkit-archive)ì„ ì„¤ì¹˜í•˜ì„¸ìš”.
3. ì„¤ì¹˜ ì¤‘ `Failed to build the SAM 2 CUDA extension`ê³¼ ê°™ì€ ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë©´ ë¬´ì‹œí•˜ê³  SAM 2ë¥¼ ê³„ì† ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì¼ë¶€ í›„ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ê²°ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤).

ì ì¬ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…ì— ëŒ€í•œ FAQëŠ” [`INSTALL.md`](./INSTALL.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ì‹œì‘í•˜ê¸°

### ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ

ë¨¼ì € ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë“  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ëŠ” ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
cd checkpoints && \
./download_ckpts.sh && \
cd ..
```

ë˜ëŠ” ê°œë³„ì ìœ¼ë¡œ ë‹¤ìŒì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- [sam2.1_hiera_tiny.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt)
- [sam2.1_hiera_small.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt)
- [sam2.1_hiera_base_plus.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt)
- [sam2.1_hiera_large.pt](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt)

(ì´ë“¤ì€ SAM 2.1ë¡œ ëª…ëª…ëœ ê°œì„ ëœ ì²´í¬í¬ì¸íŠ¸ì…ë‹ˆë‹¤; ìì„¸í•œ ë‚´ìš©ì€ [ëª¨ë¸ ì„¤ëª…](#model-description)ì„ ì°¸ì¡°í•˜ì„¸ìš”.)

ê·¸ëŸ° ë‹¤ìŒ SAM 2ëŠ” ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ì˜ˆì¸¡ì„ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ëª‡ ì¤„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì´ë¯¸ì§€ ì˜ˆì¸¡

SAM 2ëŠ” ì •ì  ì´ë¯¸ì§€ì—ì„œ [SAM](https://github.com/facebookresearch/segment-anything)ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì´ë¯¸ì§€ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ìœ„í•´ SAMê³¼ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì˜ˆì¸¡ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. `SAM2ImagePredictor` í´ë˜ìŠ¤ëŠ” ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

```python
import torch
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

checkpoint = "./checkpoints/sam2.1_hiera_large.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    predictor.set_image(<your_image>)
    masks, _, _ = predictor.predict(<input_prompts>)
```

ì •ì  ì´ë¯¸ì§€ ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•œ ì˜ˆì œëŠ” [image_predictor_example.ipynb](./notebooks/image_predictor_example.ipynb) (Colabì—ì„œë„ [ì—¬ê¸°](https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/image_predictor_example.ipynb)ì—ì„œ í™•ì¸ ê°€ëŠ¥)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

SAM 2ëŠ” ë˜í•œ SAMê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì´ë¯¸ì§€ì—ì„œ ìë™ ë§ˆìŠ¤í¬ ìƒì„±ì„ ì§€ì›í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ ìë™ ë§ˆìŠ¤í¬ ìƒì„±ì„ ìœ„í•œ ì˜ˆì œëŠ” [automatic_mask_generator_example.ipynb](./notebooks/automatic_mask_generator_example.ipynb) (Colabì—ì„œë„ [ì—¬ê¸°](https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/automatic_mask_generator_example.ipynb)ì—ì„œ í™•ì¸ ê°€ëŠ¥)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### ë¹„ë””ì˜¤ ì˜ˆì¸¡

ë¹„ë””ì˜¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ëŠ¥í•œ ì„¸ê·¸ë¨¼íŠ¸í™” ë° ì¶”ì ì„ ìœ„í•´, ìš°ë¦¬ëŠ” ë¹„ë””ì˜¤ ì˜ˆì¸¡ê¸°ë¥¼ ì œê³µí•˜ë©°, ì˜ˆë¥¼ ë“¤ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ê³  ë¹„ë””ì˜¤ ì „ì²´ì— ë§ˆìŠ¤í¬ë¥¼ ì „íŒŒí•˜ëŠ” APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. SAM 2ëŠ” ì—¬ëŸ¬ ê°ì²´ì— ëŒ€í•œ ë¹„ë””ì˜¤ ì¶”ë¡ ì„ ì§€ì›í•˜ë©°, ê° ë¹„ë””ì˜¤ì˜ ìƒí˜¸ì‘ìš©ì„ ì¶”ì í•˜ê¸° ìœ„í•´ ì¶”ë¡  ìƒíƒœë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
import torch
from sam2.build_sam import build_sam2_video_predictor

checkpoint = "./checkpoints/sam2.1_hiera_large.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
predictor = build_sam2_video_predictor(model_cfg, checkpoint)

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    state = predictor.init_state(<your_video>)

    # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ê³  ë™ì¼í•œ í”„ë ˆì„ì—ì„œ ì¦‰ì‹œ ì¶œë ¥ì„ ì–»ìŠµë‹ˆë‹¤
    frame_idx, object_ids, masks = predictor.add_new_points_or_box(state, <your_prompts>):

    # í”„ë¡¬í”„íŠ¸ë¥¼ ì „íŒŒí•˜ì—¬ ë¹„ë””ì˜¤ ì „ì²´ì— ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...
```

ë¹„ë””ì˜¤ì—ì„œ í´ë¦­ ë˜ëŠ” ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ê³ , ìˆ˜ì •í•˜ê³ , ì—¬ëŸ¬ ê°ì²´ë¥¼ ì¶”ì í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [video_predictor_example.ipynb](./notebooks/video_predictor_example.ipynb) (Colabì—ì„œë„ [ì—¬ê¸°](https://colab.research.google.com/github/facebookresearch/sam2/blob/main/notebooks/video_predictor_example.ipynb)ì—ì„œ í™•ì¸ ê°€ëŠ¥)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ¤— Hugging Faceì—ì„œ ë¡œë“œí•˜ê¸°

ëŒ€ì•ˆìœ¼ë¡œ, ëª¨ë¸ì€ [Hugging Face](https://huggingface.co/models?search=facebook/sam2)ì—ì„œ ë¡œë“œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (`pip install huggingface_hub` í•„ìš”).

ì´ë¯¸ì§€ ì˜ˆì¸¡ì˜ ê²½ìš°:

```python
import torch
from sam2.sam2_image_predictor import SAM2ImagePredictor

predictor = SAM2ImagePredictor.from_pretrained("facebook/sam2-hiera-large")

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    predictor.set_image(<your_image>)
    masks, _, _ = predictor.predict(<input_prompts>)
```

ë¹„ë””ì˜¤ ì˜ˆì¸¡ì˜ ê²½ìš°:

```python
import torch
from sam2.sam2_video_predictor import SAM2VideoPredictor

predictor = SAM2VideoPredictor.from_pretrained("facebook/sam2-hiera-large")

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    state = predictor.init_state(<your_video>)

    # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ê³  ë™ì¼í•œ í”„ë ˆì„ì—ì„œ ì¦‰ì‹œ ì¶œë ¥ì„ ì–»ìŠµë‹ˆë‹¤
    frame_idx, object_ids, masks = predictor.add_new_points_or_box(state, <your_prompts>):

    # í”„ë¡¬í”„íŠ¸ë¥¼ ì „íŒŒí•˜ì—¬ ë¹„ë””ì˜¤ ì „ì²´ì— ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...
```

## ëª¨ë¸ ì„¤ëª…

### SAM 2.1 ì²´í¬í¬ì¸íŠ¸

ì•„ë˜ í‘œëŠ” 2024ë…„ 9ì›” 29ì¼ì— ì¶œì‹œëœ ê°œì„ ëœ SAM 2.1 ì²´í¬í¬ì¸íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
|      **ëª¨ë¸**       | **í¬ê¸° (M)** |    **ì†ë„ (FPS)**     | **SA-V í…ŒìŠ¤íŠ¸ (J&F)** | **MOSE ê²€ì¦ (J&F)** | **LVOS v2 (J&F)** |
| :------------------: | :----------: | :--------------------: | :-----------------: | :----------------: | :---------------: |
|   sam2.1_hiera_tiny <br /> ([config](sam2/configs/sam2.1/sam2.1_hiera_t.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt))    |     38.9     |          91.2          |        76.5         |        71.8        |       77.3        |
|   sam2.1_hiera_small <br /> ([config](sam2/configs/sam2.1/sam2.1_hiera_s.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt))   |      46      |          84.8          |        76.6         |        73.5        |       78.3        |
| sam2.1_hiera_base_plus <br /> ([config](sam2/configs/sam2.1/sam2.1_hiera_b+.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt)) |     80.8     |        64.1          |        78.2         |        73.7        |       78.2        |
|   sam2.1_hiera_large <br /> ([config](sam2/configs/sam2.1/sam2.1_hiera_l.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt))   |    224.4     |          39.5          |        79.5         |        74.6        |       80.6        |

### SAM 2 ì²´í¬í¬ì¸íŠ¸

2024ë…„ 7ì›” 29ì¼ì— ì¶œì‹œëœ ì´ì „ SAM 2 ì²´í¬í¬ì¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

|      **ëª¨ë¸**       | **í¬ê¸° (M)** |    **ì†ë„ (FPS)**     | **SA-V í…ŒìŠ¤íŠ¸ (J&F)** | **MOSE ê²€ì¦ (J&F)** | **LVOS v2 (J&F)** |
| :------------------: | :----------: | :--------------------: | :-----------------: | :----------------: | :---------------: |
|   sam2_hiera_tiny <br /> ([config](sam2/configs/sam2/sam2_hiera_t.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt))   |     38.9     |          91.5          |        75.0         |        70.9        |       75.3        |
|   sam2_hiera_small <br /> ([config](sam2/configs/sam2/sam2_hiera_s.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt))   |      46      |          85.6          |        74.9         |        71.5        |       76.4        |
| sam2_hiera_base_plus <br /> ([config](sam2/configs/sam2/sam2_hiera_b+.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt)) |     80.8     |     64.8    |        74.7         |        72.8        |       75.8        |
|   sam2_hiera_large <br /> ([config](sam2/configs/sam2/sam2_hiera_l.yaml), [checkpoint](https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt))   |    224.4     | 39.7 |        76.0         |        74.6        |       79.8        |

ì†ë„ëŠ” `torch 2.5.1, cuda 12.4`ë¥¼ ì‚¬ìš©í•œ A100ì—ì„œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí‚¹ ì˜ˆì œëŠ” `benchmark.py`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš” (ëª¨ë¸ êµ¬ì„± ìš”ì†Œë¥¼ ëª¨ë‘ ì»´íŒŒì¼). ì´ë¯¸ì§€ ì¸ì½”ë”ë§Œ ì»´íŒŒì¼í•˜ë©´ ë” ìœ ì—°í•˜ê³  (ì‘ì€) ì†ë„ í–¥ìƒì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (êµ¬ì„±ì—ì„œ `compile_image_encoder: True`ë¡œ ì„¤ì •).

## Segment Anything Video ë°ì´í„°ì…‹

ìì„¸í•œ ë‚´ìš©ì€ [sav_dataset/README.md](sav_dataset/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## SAM 2 í›ˆë ¨

ì´ë¯¸ì§€, ë¹„ë””ì˜¤ ë˜ëŠ” ë‘˜ ë‹¤ì˜ ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì—ì„œ SAM 2ë¥¼ í›ˆë ¨í•˜ê±°ë‚˜ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œì‘í•˜ëŠ” ë°©ë²•ì€ í›ˆë ¨ [README](training/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## SAM 2 ì›¹ ë°ëª¨

SAM 2 ì›¹ ë°ëª¨ì˜ í”„ë¡ íŠ¸ì—”ë“œ + ë°±ì—”ë“œ ì½”ë“œê°€ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤ (https://sam2.metademolab.com/demoì™€ ìœ ì‚¬í•œ ë¡œì»¬ ë°°í¬ ê°€ëŠ¥í•œ ë²„ì „). ìì„¸í•œ ë‚´ìš©ì€ ì›¹ ë°ëª¨ [README](demo/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## ë¼ì´ì„ ìŠ¤

SAM 2 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸, SAM 2 ë°ëª¨ ì½”ë“œ (í”„ë¡ íŠ¸ì—”ë“œ ë° ë°±ì—”ë“œ), SAM 2 í›ˆë ¨ ì½”ë“œëŠ” [Apache 2.0](./LICENSE) ë¼ì´ì„ ìŠ¤ í•˜ì— ì œê³µë˜ì§€ë§Œ, SAM 2 ë°ëª¨ ì½”ë“œì—ì„œ ì‚¬ìš©ëœ [Inter Font](https://github.com/rsms/inter?tab=OFL-1.1-1-ov-file)ì™€ [Noto Color Emoji](https://github.com/googlefonts/noto-emoji)ëŠ” [SIL Open Font License, version 1.1](https://openfontlicense.org/open-font-license-official-text/) í•˜ì— ì œê³µë©ë‹ˆë‹¤.

## ê¸°ì—¬í•˜ê¸°

[ê¸°ì—¬í•˜ê¸°](CONTRIBUTING.md) ë° [í–‰ë™ ê°•ë ¹](CODE_OF_CONDUCT.md)ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ê¸°ì—¬ì

SAM 2 í”„ë¡œì íŠ¸ëŠ” ë§ì€ ê¸°ì—¬ìë“¤ì˜ ë„ì›€ìœ¼ë¡œ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤ (ì•ŒíŒŒë²³ ìˆœ):

Karen Bergan, Daniel Bolya, Alex Bosenberg, Kai Brown, Vispi Cassod, Christopher Chedeau, Ida Cheng, Luc Dahlin, Shoubhik Debnath, Rene Martinez Doehner, Grant Gardner, Sahir Gomez, Rishi Godugu, Baishan Guo, Caleb Ho, Andrew Huang, Somya Jain, Bob Kamma, Amanda Kallet, Jake Kinney, Alexander Kirillov, Shiva Koduvayur, Devansh Kukreja, Robert Kuo, Aohan Lin, Parth Malani, Jitendra Malik, Mallika Malhotra, Miguel Martin, Alexander Miller, Sasha Mitts, William Ngan, George Orlin, Joelle Pineau, Kate Saenko, Rodrick Shepard, Azita Shokrpour, David Soofian, Jonathan Torres, Jenny Truong, Sagar Vaze, Meng Wang, Claudette Ward, Pengchuan Zhang.

ì„œë“œíŒŒí‹° ì½”ë“œ: ìš°ë¦¬ëŠ” ë§ˆìŠ¤í¬ ì˜ˆì¸¡ì„ ìœ„í•œ ì„ íƒì  í›„ì²˜ë¦¬ ë‹¨ê³„ë¡œ [`cc_torch`](https://github.com/zsef123/Connected_components_PyTorch)ì—ì„œ ì ì‘ëœ GPU ê¸°ë°˜ ì—°ê²° êµ¬ì„± ìš”ì†Œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (ê·¸ ë¼ì´ì„ ìŠ¤ëŠ” [`LICENSE_cctorch`](./LICENSE_cctorch)ì— ìˆìŠµë‹ˆë‹¤).

## SAM 2 ì¸ìš©í•˜ê¸°

ì—°êµ¬ì—ì„œ SAM 2 ë˜ëŠ” SA-V ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ë‹¤ìŒ BibTeX í•­ëª©ì„ ì‚¬ìš©í•˜ì„¸ìš”.

```bibtex
@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2408.00714},
  url={https://arxiv.org/abs/2408.00714},
  year={2024}
}
```
